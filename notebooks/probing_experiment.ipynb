{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baad35b8",
   "metadata": {},
   "source": [
    "# Probing Experiment on SSL Models\n",
    "\n",
    "This is effectively a notebook-ized version of the old experiment runner script. It compartmentalizes everything so we don't lose state between small errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22bdeb2",
   "metadata": {},
   "source": [
    "### Imports, Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f0a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables before imports\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# Imports\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import wandb\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from src.models.feature_extractor import FeatureExtractor, load_feature_extractor\n",
    "from src.datasets.shapenet_3dr2n2 import create_3dr2n2_dataloaders\n",
    "from src.probing.probes import create_probe, ProbeTrainer\n",
    "from src.probing.data_preprocessing import (\n",
    "    FeatureExtractorPipeline,\n",
    "    create_probing_dataloaders,\n",
    "    ProbingDataset,\n",
    ")\n",
    "from src.probing.metrics import (\n",
    "    compute_regression_metrics,\n",
    "    compute_viewpoint_specific_metrics,\n",
    "    MetricsTracker,\n",
    ")\n",
    "from src.analysis.layer_analysis import LayerWiseAnalyzer\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8a3bb",
   "metadata": {},
   "source": [
    "### Probing Setup\n",
    "This class is the overarching \"manager\" that is responsible for the entire experiment. It contains all the functionalities required to:\n",
    "\n",
    "- Create & setup dataloaders \n",
    "- Extract features from the frozen layers of the ViT models \n",
    "- Train MLP & Linear probes on those layers \n",
    "- Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3034b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbingExperiment:\n",
    "    \"\"\"Orchestrates probing experiments\"\"\"\n",
    "\n",
    "    def __init__(self, config: DictConfig):\n",
    "        self.config = config\n",
    "        # Determine device: prioritize models.device, then top-level device, then auto-detect\n",
    "        device_to_use = config.models.get(\"device\", config.get(\"device\"))\n",
    "        if device_to_use:\n",
    "            self.device = device_to_use\n",
    "        else:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "\n",
    "        # Initialize wandb\n",
    "        if config.get(\"wandb\", {}).get(\"enabled\", False):\n",
    "            wandb.init(\n",
    "                project=config.wandb.project,\n",
    "                entity=config.wandb.get(\"entity\"),\n",
    "                name=config.experiment.name,\n",
    "                config=OmegaConf.to_container(config, resolve=True),\n",
    "            )\n",
    "\n",
    "        # Setup paths\n",
    "        self.results_dir = Path(config.get(\"results_dir\", \"./results\"))\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.cache_dir = Path(config.get(\"cache_dir\", \"./cache\"))\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Setup probe save directory\n",
    "        self.probe_save_dir = self.cache_dir / \"probes\" / self.config.experiment.name\n",
    "        self.probe_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Initialize analyzer\n",
    "        self.analyzer = LayerWiseAnalyzer(self.results_dir / config.experiment.name)\n",
    "\n",
    "   \n",
    "    def load_dataset(self) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "        \"\"\"Load the dataset\"\"\"\n",
    "        subset_percentage = self.config.datasets.get(\"subset_percentage\", None)\n",
    "        return create_3dr2n2_dataloaders(\n",
    "            self.config.datasets, subset_percentage=subset_percentage\n",
    "        )\n",
    "\n",
    "    def load_feature_extractor(self) -> FeatureExtractor:\n",
    "        \"\"\"Load and setup feature extractor\"\"\"\n",
    "        model_config = self.config.models\n",
    "        model_config.device = self.device\n",
    "        model_config.cache_dir = str(self.cache_dir / \"models\")\n",
    "\n",
    "        feature_extractor = load_feature_extractor(OmegaConf.to_container(model_config))\n",
    "        logger.info(f\"Loaded {model_config.model_name} feature extractor\")\n",
    "        return feature_extractor\n",
    "\n",
    "    def extract_features_for_layer(\n",
    "        self,\n",
    "        feature_extractor: FeatureExtractor,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        test_loader: DataLoader,\n",
    "        layer: int,\n",
    "        feature_type: str,\n",
    "        task_type: str,\n",
    "    ) -> Tuple[ProbingDataset, ProbingDataset, ProbingDataset]:\n",
    "        \"\"\"Extract features for a specific layer\"\"\"\n",
    "        pipeline = FeatureExtractorPipeline(\n",
    "            feature_extractor=feature_extractor,\n",
    "            device=self.device,\n",
    "            batch_size=self.config.get(\"extraction_batch_size\", 32),\n",
    "            cache_dir=str(self.cache_dir / \"features\"),\n",
    "        )\n",
    "\n",
    "        experiment_name = f\"{self.config.models.model_name}_{self.config.experiment.name}_layer_{layer}\"\n",
    "\n",
    "        return pipeline.create_probing_datasets(\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            layers=[layer],\n",
    "            feature_type=feature_type,\n",
    "            task_type=task_type,\n",
    "            experiment_name=experiment_name,\n",
    "        )\n",
    "\n",
    "    def run_probe_experiment(\n",
    "        self,\n",
    "        probe_type: str,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        test_loader: DataLoader,\n",
    "        feature_dim: int,\n",
    "        layer: int,\n",
    "    ) -> Dict:\n",
    "        \"\"\"Run a single probe experiment\"\"\"\n",
    "\n",
    "        logger.info(\n",
    "            f\"Running {probe_type} probe on layer {layer} (feature_dim: {feature_dim})\"\n",
    "        )\n",
    "\n",
    "        # Get probe configuration\n",
    "        probe_config = self.config.probing.get(probe_type, {})\n",
    "        # Make a mutable copy for modification\n",
    "        probe_config = OmegaConf.to_container(probe_config, resolve=True)\n",
    "\n",
    "        # Create probe\n",
    "        probe_config[\"input_dim\"] = feature_dim\n",
    "        probe_config[\"output_dim\"] = self.config.probing.get(\"output_dim\", 2)\n",
    "\n",
    "        main_task_type = self.config.probing.get(\"task_type\", \"regression\")\n",
    "        if main_task_type == \"viewpoint_regression\":\n",
    "            probe_config[\"task_type\"] = \"regression\"\n",
    "        elif main_task_type == \"view_classification\":\n",
    "            probe_config[\"task_type\"] = \"classification\"\n",
    "        else:\n",
    "            probe_config[\"task_type\"] = main_task_type\n",
    "\n",
    "        probe = create_probe(probe_config)\n",
    "\n",
    "        # Setup trainer\n",
    "        trainer = ProbeTrainer(probe, device=self.device)\n",
    "\n",
    "        # Setup optimizer and scheduler\n",
    "        training_config = probe_config.get(\"training\", {})\n",
    "        optimizer = self.create_optimizer(probe, training_config.get(\"optimizer\", {}))\n",
    "        scheduler = self.create_scheduler(\n",
    "            optimizer, training_config.get(\"scheduler\", {})\n",
    "        )\n",
    "\n",
    "        # Training parameters\"results/phase1_dinov2_viewpoint_probing/results.json\"\n",
    "        epochs = training_config.get(\"epochs\", 30)\n",
    "        early_stopping_patience = training_config.get(\"early_stopping_patience\", 15)\n",
    "\n",
    "        metrics_tracker = MetricsTracker()\n",
    "        trainer = ProbeTrainer(\n",
    "            probe, device=self.device, MetricsTracker=metrics_tracker\n",
    "        )\n",
    "\n",
    "        # Check if wandb is enabled\n",
    "        wandb_enabled = self.config.get(\"wandb\", {}).get(\"enabled\", False)\n",
    "\n",
    "        best_model, best_val_loss = trainer.train(\n",
    "            epochs,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            early_stopping_patience,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            probe_type=probe_type,\n",
    "            layer=layer,\n",
    "            wandb_enabled=wandb_enabled,\n",
    "        )\n",
    "        \n",
    "        # Save the trained probe\n",
    "        probe_save_dir = self.cache_dir / \"probes\" / self.config.experiment.name\n",
    "        probe_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        probe_filename = f\"{probe_type}_layer_{layer}_probe.pth\"\n",
    "        probe_save_path = probe_save_dir / probe_filename\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': best_model,  # best_model is already a state_dict\n",
    "            'probe_config': probe_config,\n",
    "            'layer': layer,\n",
    "            'probe_type': probe_type,\n",
    "            'experiment_name': self.config.experiment.name,\n",
    "            'model_name': self.config.models.model_name,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'feature_dim': feature_dim\n",
    "        }, probe_save_path)\n",
    "        \n",
    "        logger.info(f\"Saved {probe_type} probe for layer {layer} to {probe_save_path}\")\n",
    "\n",
    "        test_metrics = trainer.evaluate(test_loader)\n",
    "\n",
    "        detailed_metrics = self.compute_detailed_metrics(probe, test_loader)\n",
    "\n",
    "        total_epochs = len(metrics_tracker.get_history(\"train\"))\n",
    "\n",
    "        results = {\n",
    "            \"train_history\": metrics_tracker.get_history(\"train\"),\n",
    "            \"val_history\": metrics_tracker.get_history(\"val\"),\n",
    "            \"test_metrics\": test_metrics,\n",
    "            \"detailed_metrics\": detailed_metrics,\n",
    "            \"best_epoch\": metrics_tracker.best_epoch,\n",
    "            \"total_epochs\": total_epochs,\n",
    "        }\n",
    "\n",
    "        return results\n",
    "\n",
    "    def save_probe(self, probe: nn.Module, probe_type: str, layer: int, probe_config: Dict):\n",
    "        \"\"\"Save the trained probe model and its configuration\"\"\"\n",
    "        import json\n",
    "        \n",
    "        # Create filename with model name, probe type, and layer\n",
    "        model_name = self.config.models.model_name\n",
    "        filename = f\"{model_name}_{probe_type}_layer_{layer}.pth\"\n",
    "        probe_path = self.probe_save_dir / filename\n",
    "        \n",
    "        # Save the probe state dict\n",
    "        torch.save({\n",
    "            'model_state_dict': probe.state_dict(),\n",
    "            'probe_config': probe_config,\n",
    "            'model_name': model_name,\n",
    "            'probe_type': probe_type,\n",
    "            'layer': layer,\n",
    "            'experiment_name': self.config.experiment.name\n",
    "        }, probe_path)\n",
    "        \n",
    "        # Also save the config as JSON\n",
    "        config_filename = f\"{model_name}_{probe_type}_layer_{layer}_config.json\"\n",
    "        config_path = self.probe_save_dir / config_filename\n",
    "        \n",
    "        with open(config_path, 'w') as f:\n",
    "            json.dump({\n",
    "                'probe_config': probe_config,\n",
    "                'model_name': model_name,\n",
    "                'probe_type': probe_type,\n",
    "                'layer': layer,\n",
    "                'experiment_name': self.config.experiment.name\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        logger.info(f\"Probe saved to {probe_path}\")\n",
    "        logger.info(f\"Probe config saved to {config_path}\")\n",
    "\n",
    "    def load_probe(self, probe_type: str, layer: int, device: Optional[str] = None) -> nn.Module:\n",
    "        \"\"\"Load a previously saved probe\"\"\"\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "            \n",
    "        model_name = self.config.models.model_name\n",
    "        filename = f\"{model_name}_{probe_type}_layer_{layer}.pth\"\n",
    "        probe_path = self.probe_save_dir / filename\n",
    "        \n",
    "        if not probe_path.exists():\n",
    "            raise FileNotFoundError(f\"Probe not found at {probe_path}\")\n",
    "        \n",
    "        # Load the saved data\n",
    "        saved_data = torch.load(probe_path, map_location=device)\n",
    "        \n",
    "        # Recreate the probe using the saved config\n",
    "        probe_config = saved_data['probe_config']\n",
    "        probe = create_probe(probe_config)\n",
    "        \n",
    "        # Load the state dict\n",
    "        probe.load_state_dict(saved_data['model_state_dict'])\n",
    "        probe.to(device)\n",
    "        \n",
    "        logger.info(f\"Probe loaded from {probe_path}\")\n",
    "        return probe\n",
    "\n",
    "    def create_optimizer(\n",
    "        self, model: nn.Module, optimizer_config: Dict\n",
    "    ) -> torch.optim.Optimizer:\n",
    "        \"\"\"Create optimizer from config using Hydra instantiate\"\"\"\n",
    "        from hydra.utils import instantiate\n",
    "\n",
    "        # Create a copy of config and add model parameters\n",
    "        optimizer_config = optimizer_config.copy()\n",
    "        optimizer_config[\"params\"] = model.parameters()\n",
    "\n",
    "        return instantiate(optimizer_config)\n",
    "\n",
    "    def create_scheduler(\n",
    "        self, optimizer: torch.optim.Optimizer, scheduler_config: Dict\n",
    "    ):\n",
    "        \"\"\"Create learning rate scheduler from config using Hydra instantiate\"\"\"\n",
    "        if not scheduler_config:\n",
    "            return None\n",
    "\n",
    "        from hydra.utils import instantiate\n",
    "\n",
    "        scheduler_config = scheduler_config.copy()\n",
    "        scheduler_config[\"optimizer\"] = optimizer\n",
    "\n",
    "        return instantiate(scheduler_config)\n",
    "\n",
    "    def compute_detailed_metrics(\n",
    "        self, probe: nn.Module, test_loader: DataLoader\n",
    "    ) -> Dict:\n",
    "        \"\"\"Compute alles metrics\"\"\"\n",
    "        probe.eval()\n",
    "\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        all_categories = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                features = batch[\"features\"].to(self.device)\n",
    "                targets = batch[\"targets\"]\n",
    "\n",
    "                outputs = probe(features)\n",
    "\n",
    "                all_predictions.append(outputs.cpu())\n",
    "                all_targets.append(targets)\n",
    "\n",
    "                # Get categories if available\n",
    "                if \"categories\" in batch:\n",
    "                    all_categories.extend(batch[\"categories\"])\n",
    "\n",
    "        predictions = torch.cat(all_predictions, dim=0)\n",
    "        targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "        # Basic regression metrics\n",
    "        metrics = compute_regression_metrics(predictions, targets, return_per_dim=True)\n",
    "\n",
    "        # Viewpoint-specific metrics\n",
    "        if predictions.shape[1] == 2:\n",
    "            viewpoint_metrics = compute_viewpoint_specific_metrics(\n",
    "                azimuth_pred=predictions[:, 0],\n",
    "                elevation_pred=predictions[:, 1],\n",
    "                azimuth_target=targets[:, 0],\n",
    "                elevation_target=targets[:, 1],\n",
    "            )\n",
    "            metrics.update(viewpoint_metrics)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def save_results(self, results: Dict) -> str:\n",
    "        \"\"\"Save results to disk\"\"\"\n",
    "        import json\n",
    "\n",
    "        # Create experiment directory\n",
    "        exp_dir = self.results_dir / self.config.experiment.name\n",
    "        exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Save results\n",
    "        results_file = exp_dir / \"results.json\"\n",
    "\n",
    "        # Convert tensors to lists for JSON serialization\n",
    "        serializable_results = self.make_json_serializable(results)\n",
    "\n",
    "        combined_results = {\n",
    "            \"config\": OmegaConf.to_container(self.config, resolve=True),\n",
    "            \"results\": serializable_results,\n",
    "        }\n",
    "\n",
    "        with open(results_file, \"w\") as f:\n",
    "            json.dump(combined_results, f, indent=2)\n",
    "\n",
    "        logger.info(f\"Results saved to {results_file}\")\n",
    "        return results_file\n",
    "\n",
    "    def make_json_serializable(self, obj):\n",
    "        \"\"\"Convert object to JSON-serializable format\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: self.make_json_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.make_json_serializable(v) for v in obj]\n",
    "        elif isinstance(obj, (torch.Tensor, np.ndarray)):\n",
    "            return obj.tolist() if hasattr(obj, \"tolist\") else float(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        else:\n",
    "            return obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb324d",
   "metadata": {},
   "source": [
    "### Hydra Configuration Loading / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3296c249",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 21:40:30,706 - __main__ - INFO - Initializing Hydra with config_path: '../configs'\n",
      "2025-06-01 21:40:31,183 - __main__ - INFO - Composing configuration with config_name: 'experiment_config'\n",
      "2025-06-01 21:40:31,268 - __main__ - INFO - Hydra configuration loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "import os \n",
    "from pathlib import Path #\n",
    "\n",
    "CONFIG_PATH = \"../configs\"\n",
    "CONFIG_NAME = \"experiment_config\"\n",
    "\n",
    "cfg: Optional[DictConfig] = None\n",
    "\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    logger.info(\"Clearing existing Hydra global state.\")\n",
    "    GlobalHydra.instance().clear()\n",
    "\n",
    "try:\n",
    "    project_root = Path(os.getcwd()).parent \n",
    "    data_dir_abs = project_root / \"data\"\n",
    "    \n",
    "    os.environ[\"DATA_DIR\"] = str(data_dir_abs)\n",
    "\n",
    "    logger.info(f\"Initializing Hydra with config_path: '{CONFIG_PATH}'\")\n",
    "    \n",
    "    initialize(version_base=None, config_path=CONFIG_PATH)\n",
    "    \n",
    "    logger.info(f\"Composing configuration with config_name: '{CONFIG_NAME}'\")\n",
    "    \n",
    "    cfg = compose(config_name=CONFIG_NAME)\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Hydra or loading configuration: {e}\", exc_info=True)\n",
    "\n",
    "if cfg:\n",
    "    logger.info(\"Hydra configuration loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d9168",
   "metadata": {},
   "source": [
    "## Running the Experiment\n",
    "The following code uses the above configurations and utility functions to run the actual experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69efd063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 21:40:31,285 - __main__ - INFO - Starting experiment execution\n",
      "2025-06-01 21:40:31,285 - __main__ - INFO - Using device: cuda\n",
      "2025-06-01 21:40:31,528 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: rsen0811 (cse493g1_drn). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.11 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\stunt\\OneDrive\\Documents\\GitHub\\LatentInvestigation\\notebooks\\wandb\\run-20250601_214032-cqbb54wp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cse493g1_drn/latent-investigation/runs/cqbb54wp' target=\"_blank\">phase1_dinov2_viewpoint_probing</a></strong> to <a href='https://wandb.ai/cse493g1_drn/latent-investigation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cse493g1_drn/latent-investigation' target=\"_blank\">https://wandb.ai/cse493g1_drn/latent-investigation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cse493g1_drn/latent-investigation/runs/cqbb54wp' target=\"_blank\">https://wandb.ai/cse493g1_drn/latent-investigation/runs/cqbb54wp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = None\n",
    "logger.info(\"Starting experiment execution\")\n",
    "experiment = ProbingExperiment(cfg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117dade8",
   "metadata": {},
   "source": [
    "### Load the Feature Extractor & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df34a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 21:40:37,997 - src.models.feature_extractor - INFO - Loaded dinov2 model on cuda\n",
      "2025-06-01 21:40:37,998 - __main__ - INFO - Loaded dinov2 feature extractor\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = experiment.load_feature_extractor()\n",
    "extraction_config = cfg.models.get(\"feature_extraction\", {})\n",
    "layers = extraction_config.get(\"layers\", [11])\n",
    "feature_type = extraction_config.get(\"feature_type\", \"cls_token\")\n",
    "task_type = cfg.probing.get(\"task_type\", \"viewpoint_regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713ca504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30648/30648 [01:25<00:00, 356.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5.00% of train data: 36777 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6567/6567 [00:26<00:00, 248.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5.00% of val data: 7880 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6569/6569 [00:15<00:00, 419.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 5.00% of test data: 7882 samples.\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = experiment.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642e0c9",
   "metadata": {},
   "source": [
    "### Train the Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44c89e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]2025-06-01 21:55:26,030 - __main__ - INFO - Processing layer 2...\n",
      "2025-06-01 21:55:26,031 - src.probing.data_preprocessing - INFO - Extracting features from 1149 batches...\n",
      "\n",
      "Extracting features:   0%|          | 0/1149 [00:07<?, ?it/s]\n",
      "  0%|          | 0/6 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract features for this layer\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_dataset, val_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features_for_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create probing dataloaders\u001b[39;00m\n\u001b[0;32m     17\u001b[0m probe_train_loader, probe_val_loader, probe_test_loader \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     18\u001b[0m    create_probing_dataloaders(\n\u001b[0;32m     19\u001b[0m         train_dataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     27\u001b[0m )\n",
      "Cell \u001b[1;32mIn[2], line 78\u001b[0m, in \u001b[0;36mProbingExperiment.extract_features_for_layer\u001b[1;34m(self, feature_extractor, train_loader, val_loader, test_loader, layer, feature_type, task_type)\u001b[0m\n\u001b[0;32m     69\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m FeatureExtractorPipeline(\n\u001b[0;32m     70\u001b[0m     feature_extractor\u001b[38;5;241m=\u001b[39mfeature_extractor,\n\u001b[0;32m     71\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[0;32m     72\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextraction_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m     73\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     76\u001b[0m experiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_layer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_probing_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\LatentInvestigation\\src\\probing\\data_preprocessing.py:171\u001b[0m, in \u001b[0;36mFeatureExtractorPipeline.create_probing_datasets\u001b[1;34m(self, train_loader, val_loader, test_loader, layers, feature_type, task_type, experiment_name)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m split, dataloader \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    165\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_loader),\n\u001b[0;32m    166\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_loader),\n\u001b[0;32m    167\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loader),\n\u001b[0;32m    168\u001b[0m ]:\n\u001b[0;32m    169\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m experiment_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m     features, targets, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features_from_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m ProbingDataset(\n\u001b[0;32m    180\u001b[0m         features\u001b[38;5;241m=\u001b[39mfeatures, targets\u001b[38;5;241m=\u001b[39mtargets, metadata\u001b[38;5;241m=\u001b[39mmetadata\n\u001b[0;32m    181\u001b[0m     )\n\u001b[0;32m    182\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mappend(dataset)\n",
      "File \u001b[1;32m~\\OneDrive\\Documents\\GitHub\\LatentInvestigation\\src\\probing\\data_preprocessing.py:119\u001b[0m, in \u001b[0;36mFeatureExtractorPipeline.extract_features_from_dataloader\u001b[1;34m(self, dataloader, layers, feature_type, task_type, cache_key, force_recompute)\u001b[0m\n\u001b[0;32m    117\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(features_dict\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfeatures_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m all_features\u001b[38;5;241m.\u001b[39mappend(features\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Collect metadata\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for layer in tqdm(layers):\n",
    "    logger.info(f\"Processing layer {layer}...\")\n",
    "\n",
    "    # Extract features for this layer\n",
    "    train_dataset, val_dataset, test_dataset = experiment.extract_features_for_layer(\n",
    "        feature_extractor,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        layer,\n",
    "        feature_type,\n",
    "        task_type,\n",
    "    )\n",
    "\n",
    "    # Create probing dataloaders\n",
    "    probe_train_loader, probe_val_loader, probe_test_loader = (\n",
    "       create_probing_dataloaders(\n",
    "            train_dataset,\n",
    "            val_dataset,\n",
    "            test_dataset,\n",
    "            batch_size=cfg.probing.get(\"training\", {}).get(\n",
    "                \"batch_size\", 64\n",
    "            ),\n",
    "            num_workers=cfg.get(\"num_workers\", 4),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Run probing experiments for each probe type\n",
    "    layer_results = {}\n",
    "    for probe_type in cfg.probing.probe_types:\n",
    "        logger.info(f\"Running {probe_type} probe on layer {layer}...\")\n",
    "        probe_results = experiment.run_probe_experiment(\n",
    "            probe_type,\n",
    "            probe_train_loader,\n",
    "            probe_val_loader,\n",
    "            probe_test_loader,\n",
    "            train_dataset.features.shape[1],\n",
    "            layer,\n",
    "        )\n",
    "        layer_results[probe_type] = probe_results\n",
    "\n",
    "    results[f\"layer_{layer}\"] = layer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f1822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 20:38:53,268 - __main__ - INFO - Saving results...\n",
      "2025-06-01 20:38:53,272 - __main__ - INFO - Results saved to results/phase1_dinov2_viewpoint_probing/results.json\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Saving results...\")\n",
    "result_path = experiment.save_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706a05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-01 20:38:53,288 - __main__ - INFO - Creating analysis and visualizations...\n",
      "2025-06-01 20:38:55,227 - src.analysis.layer_analysis - INFO - Analysis report saved to analysis_results/layer_analysis_report.json\n",
      "2025-06-01 20:38:55,228 - __main__ - INFO - Results analyzed! Please see the results and analysis_results folders for the outcomes.\n"
     ]
    }
   ],
   "source": [
    "from src.analysis.layer_analysis import analyze_experiment_results\n",
    "\n",
    "logger.info(\"Creating analysis and visualizations...\")\n",
    "analyze_experiment_results(result_path, output_dir=result_path.parent)\n",
    "\n",
    "logger.info(\"Results analyzed! Please see the results and analysis_results folders for the outcomes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LatentInvestigation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
