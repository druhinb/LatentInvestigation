{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a05e8b5",
   "metadata": {},
   "source": [
    "# Reconstruction Experiment on SSL Models (iJEPa)\n",
    "\n",
    "This notebook adapts the probing experiment framework to focus on 3D voxel reconstruction using `VoxelProbe`. It will:\n",
    "- Load a pre-trained DINOv2 model.\n",
    "- Extract features from specified layers.\n",
    "- Train `VoxelProbe` instances on these features to predict 3D voxel occupancy.\n",
    "- Evaluate performance using IoU, Precision, Recall, and F1-score.\n",
    "- Analyze and visualize results to determine which layers are best for reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb671f5",
   "metadata": {},
   "source": [
    "### Imports, Logging Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95849e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables before imports\n",
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# Imports\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import wandb\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Model and dataset imports\n",
    "from src.models.reconstruction_feature_extractor import ReconstructionFeatureExtractor, load_image_feature_extractor \n",
    "from src.datasets.shapenet_voxel_meshes import create_3dr2n2_reconstruction_dataloaders \n",
    "\n",
    "# Probing imports using new modular structure\n",
    "from src.probing import (\n",
    "    create_probe, \n",
    "    ProbeTrainer,\n",
    "    ReconstructionPipeline,\n",
    "    ReconstructionDataset,\n",
    "    compute_voxel_metrics,\n",
    "    MetricsTracker,\n",
    ")\n",
    "from src.analysis.layer_analysis import LayerWiseAnalyzer\n",
    "\n",
    "# Fix duplicate logging issue in Jupyter notebooks\n",
    "# Clear any existing handlers to prevent duplicates\n",
    "root_logger = logging.getLogger()\n",
    "for handler in root_logger.handlers[:]:\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "# Configure logging fresh\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    force=True  # This forces reconfiguration in newer Python versions\n",
    ")\n",
    "\n",
    "# Get the notebook logger\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73f3059",
   "metadata": {},
   "source": [
    "### Reconstruction Experiment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e724005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructionExperiment:\n",
    "    \"\"\"Orchestrates 3D reconstruction experiments using VoxelProbes\"\"\"\n",
    "\n",
    "    def __init__(self, config: DictConfig):\n",
    "        self.config = config\n",
    "        device_to_use = config.get(\"device\", config.get(\"device\"))\n",
    "        if device_to_use:\n",
    "            self.device = device_to_use\n",
    "        else:\n",
    "            self.device = (\n",
    "                \"cuda\"\n",
    "                if torch.cuda.is_available()\n",
    "                else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "            )\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "\n",
    "        if config.get(\"wandb\", {}).get(\"enabled\", False):\n",
    "            wandb.init(\n",
    "                project=config.wandb.project,\n",
    "                entity=config.wandb.get(\"entity\"),\n",
    "                name=config.experiment.name + \"_reconstruction\", \n",
    "                config=OmegaConf.to_container(config, resolve=True),\n",
    "            )\n",
    "\n",
    "        self.results_dir = Path(config.get(\"results_dir\", \"./results\")) / (config.experiment.name)\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.cache_dir = Path(config.get(\"cache_dir\", \"./cache\")) / (config.experiment.name)\n",
    "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.probe_save_dir = self.cache_dir / \"probes\"\n",
    "        self.probe_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.analyzer = LayerWiseAnalyzer(self.results_dir)\n",
    "\n",
    "    def load_source_dataset(self) -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "        \"\"\"Load the source ShapeNet dataset with images and voxels.\"\"\"\n",
    "        subset_percentage = self.config.datasets.get(\"subset_percentage\", None)\n",
    "        return create_3dr2n2_reconstruction_dataloaders( \n",
    "            self.config.datasets, \n",
    "            batch_size=self.config.datasets.get(\"source_batch_size\", 16), \n",
    "            num_workers=self.config.get(\"num_workers\", 4),\n",
    "            subset_percentage=subset_percentage\n",
    "        )\n",
    "\n",
    "    def load_reconstruction_feature_extractor(self) -> ReconstructionFeatureExtractor:\n",
    "        \"\"\"Load and setup ReconstructionFeatureExtractor\"\"\"\n",
    "        model_config = self.config.models\n",
    "        model_config_dict = OmegaConf.to_container(model_config, resolve=True)\n",
    "        model_config_dict[\"device\"] = self.device\n",
    "        model_config_dict[\"cache_dir\"] = str(self.cache_dir / \"models\")\n",
    "        \n",
    "        feature_extractor = load_image_feature_extractor(model_config_dict)\n",
    "        logger.info(f\"Loaded {model_config_dict.get('model_name')} reconstruction feature extractor\")\n",
    "        return feature_extractor\n",
    "\n",
    "    def prepare_reconstruction_input_datasets_for_layer(\n",
    "        self,\n",
    "        reconstruction_pipeline: ReconstructionPipeline,\n",
    "        train_source_loader: DataLoader,\n",
    "        val_source_loader: DataLoader,\n",
    "        test_source_loader: DataLoader,\n",
    "        layer: int,\n",
    "        image_feature_type: str,\n",
    "    ) -> Tuple[ReconstructionDataset, ReconstructionDataset, ReconstructionDataset]:\n",
    "        \"\"\"\n",
    "        Uses ReconstructionPipeline to extract image features for a specific layer\n",
    "        and combine them with processed camera parameters, then creates datasets.\n",
    "        \"\"\"\n",
    "        experiment_id = f\"{self.config.models.model_name}_{self.config.experiment.name}_layer_{layer}\"\n",
    "        \n",
    "        # Create datasets using the new API\n",
    "        train_input_dataset = reconstruction_pipeline.create_dataset(\n",
    "            dataloader=train_source_loader,\n",
    "            layers=[layer],\n",
    "            feature_type=image_feature_type,\n",
    "            cache_key=f\"{experiment_id}_train\",\n",
    "            force_recompute=self.config.get(\"force_recompute_processed_data\", False)\n",
    "        )\n",
    "        \n",
    "        val_input_dataset = reconstruction_pipeline.create_dataset(\n",
    "            dataloader=val_source_loader,\n",
    "            layers=[layer],\n",
    "            feature_type=image_feature_type,\n",
    "            cache_key=f\"{experiment_id}_val\",\n",
    "            force_recompute=self.config.get(\"force_recompute_processed_data\", False)\n",
    "        )\n",
    "        \n",
    "        test_input_dataset = reconstruction_pipeline.create_dataset(\n",
    "            dataloader=test_source_loader,\n",
    "            layers=[layer],\n",
    "            feature_type=image_feature_type,\n",
    "            cache_key=f\"{experiment_id}_test\",\n",
    "            force_recompute=self.config.get(\"force_recompute_processed_data\", False)\n",
    "        )\n",
    "        \n",
    "        return train_input_dataset, val_input_dataset, test_input_dataset\n",
    "\n",
    "    def run_voxel_probe_experiment(\n",
    "        self,\n",
    "        train_processed_loader: DataLoader, \n",
    "        val_processed_loader: DataLoader,\n",
    "        test_processed_loader: DataLoader,\n",
    "        feature_dim: int,\n",
    "        layer: int,\n",
    "    ) -> Dict:\n",
    "        \"\"\"Run a single VoxelProbe experiment\"\"\"\n",
    "        probe_type = \"voxel\"\n",
    "        logger.info(\n",
    "            f\"Running VoxelProbe on layer {layer} (input_feature_dim: {feature_dim})\"\n",
    "        )\n",
    "\n",
    "        probe_config = self.config.probing\n",
    "        \n",
    "        probe_config[\"input_dim\"] = feature_dim\n",
    "        probe_config[\"task_type\"] = \"voxel_reconstruction\" \n",
    "        \n",
    "        self.device = probe_config.get(\"device\", self.device)\n",
    "\n",
    "        probe = create_probe(probe_config)\n",
    "        \n",
    "        metrics_tracker = MetricsTracker()\n",
    "        trainer = ProbeTrainer(\n",
    "            probe, device=self.device, MetricsTracker=metrics_tracker\n",
    "        )\n",
    "\n",
    "        training_config = self.config.probing.get(\"training\", {}) \n",
    "        optimizer_specific_config = probe_config.get(\"optimizer\", training_config.get(\"optimizer\", {}))\n",
    "        scheduler_specific_config = probe_config.get(\"scheduler\", training_config.get(\"scheduler\", {}))\n",
    "\n",
    "        optimizer = self.create_optimizer(probe, optimizer_specific_config)\n",
    "        scheduler = self.create_scheduler(optimizer, scheduler_specific_config)\n",
    "\n",
    "        epochs = training_config.get(\"epochs\", 50) # Potentially more epochs for reconstruction\n",
    "        early_stopping_patience = training_config.get(\"early_stopping_patience\", 10)\n",
    "        wandb_enabled = self.config.get(\"wandb\", {}).get(\"enabled\", False)\n",
    "\n",
    "        best_model_state_dict, best_val_loss = trainer.train(\n",
    "            epochs,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            early_stopping_patience,\n",
    "            train_processed_loader,\n",
    "            val_processed_loader,\n",
    "            probe_type=probe_type, # Pass \"voxel\"\n",
    "            layer=layer,\n",
    "            wandb_enabled=wandb_enabled,\n",
    "        )\n",
    "        \n",
    "        probe_filename = f\"{self.config.models.model_name}_{probe_type}_layer_{layer}_probe.pth\"\n",
    "        probe_save_path = self.probe_save_dir / probe_filename\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': best_model_state_dict,\n",
    "            'probe_config': probe_config, \n",
    "            'layer': layer,\n",
    "            'probe_type': probe_type,\n",
    "            'experiment_name': self.config.experiment.name,\n",
    "            'model_name': self.config.models.model_name,\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'input_feature_dim': feature_dim \n",
    "        }, probe_save_path)\n",
    "        logger.info(f\"Saved VoxelProbe for layer {layer} to {probe_save_path}\")\n",
    "\n",
    "        probe.load_state_dict(best_model_state_dict)\n",
    "       \n",
    "        test_metrics = trainer.evaluate(\n",
    "            test_loader=test_processed_loader, \n",
    "            wandb_enabled=wandb_enabled, \n",
    "            probe_type=probe_type, \n",
    "            layer=layer\n",
    "        )\n",
    "\n",
    "        detailed_metrics = self._compute_detailed_metrics(probe, test_processed_loader) \n",
    "\n",
    "        total_epochs_trained = len(metrics_tracker.get_history(\"train\"))\n",
    "\n",
    "        results = {\n",
    "            \"train_history\": metrics_tracker.get_history(\"train\"),\n",
    "            \"val_history\": metrics_tracker.get_history(\"val\"),\n",
    "            \"test_metrics\": test_metrics, \n",
    "            \"detailed_metrics\": detailed_metrics, \n",
    "            \"best_epoch\": metrics_tracker.best_epoch,\n",
    "            \"total_epochs\": total_epochs_trained,\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def create_optimizer(\n",
    "        self, model: nn.Module, optimizer_config: Dict\n",
    "    ) -> torch.optim.Optimizer:\n",
    "        from hydra.utils import instantiate\n",
    "        opt_config_copy = OmegaConf.create(optimizer_config) \n",
    "        if \"_target_\" not in opt_config_copy: \n",
    "             raise ValueError(\"Optimizer config must have a _target_ field\")\n",
    "\n",
    "        return instantiate(opt_config_copy, params=model.parameters())\n",
    "\n",
    "\n",
    "    def create_scheduler(\n",
    "        self, optimizer: torch.optim.Optimizer, scheduler_config: Dict\n",
    "    ):\n",
    "        if not scheduler_config or not scheduler_config.get(\"_target_\"): \n",
    "            return None\n",
    "        from hydra.utils import instantiate\n",
    "        sched_config_copy = OmegaConf.create(scheduler_config)\n",
    "        return instantiate(sched_config_copy, optimizer=optimizer)\n",
    "\n",
    "    def _compute_detailed_metrics( \n",
    "        self, probe: nn.Module, test_loader: DataLoader \n",
    "    ) -> Dict:\n",
    "        \n",
    "        probe.to(self.device)\n",
    "        probe.eval()\n",
    "        all_predictions = [] \n",
    "        all_targets = []   \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Computing detailed metrics\"):\n",
    "                features = batch[\"processed_views\"].to(self.device) \n",
    "                targets = batch[\"target_voxels\"].to(self.device) \n",
    "\n",
    "                if probe.task_type == \"voxel_reconstruction\":\n",
    "                    features = features.view(features.size(0), -1)\n",
    "\n",
    "                outputs = probe(features) # Voxel logits: [B, 1, D, H, W]\n",
    "\n",
    "                all_predictions.append(outputs.cpu()) \n",
    "                all_targets.append(targets.cpu())\n",
    "\n",
    "        predictions_cat = torch.cat(all_predictions, dim=0)\n",
    "        targets_cat = torch.cat(all_targets, dim=0)\n",
    "        \n",
    "        metrics = {}\n",
    "        voxel_eval_metrics = compute_voxel_metrics(predictions_cat, targets_cat)\n",
    "        metrics.update(voxel_eval_metrics)\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def save_results(self, results: Dict) -> str:\n",
    "        import json\n",
    "        results_file = self.results_dir / \"reconstruction_results.json\"\n",
    "        serializable_results = self.make_json_serializable(results)\n",
    "        combined_results = {\n",
    "            \"config\": OmegaConf.to_container(self.config, resolve=True),\n",
    "            \"results\": serializable_results,\n",
    "        }\n",
    "        with open(results_file, \"w\") as f:\n",
    "            json.dump(combined_results, f, indent=2)\n",
    "        logger.info(f\"Reconstruction results saved to {results_file}\")\n",
    "        return str(results_file)\n",
    "\n",
    "    def make_json_serializable(self, obj):\n",
    "        if isinstance(obj, dict):\n",
    "            return {k: self.make_json_serializable(v) for k, v in obj.items()}\n",
    "        elif isinstance(obj, list):\n",
    "            return [self.make_json_serializable(v) for v in obj]\n",
    "        elif isinstance(obj, (torch.Tensor, np.ndarray)):\n",
    "            return obj.tolist() if hasattr(obj, \"tolist\") else float(obj)\n",
    "        elif isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, Path):\n",
    "            return str(obj)\n",
    "        else:\n",
    "            return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd6ad5",
   "metadata": {},
   "source": [
    "### Hydra Configuration Loading / Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7937ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:09:10,414 - __main__ - INFO - Initializing Hydra with config_path: '../configs' relative to /Users/druhi/Documents/+Programming/GitHub/LatentInvestigation/notebooks\n",
      "2025-06-05 00:09:10,577 - __main__ - INFO - Composing configuration with config_name: 'exp_ijepa_reconstruction'\n",
      "2025-06-05 00:09:10,577 - __main__ - INFO - Composing configuration with config_name: 'exp_ijepa_reconstruction'\n",
      "2025-06-05 00:09:10,635 - __main__ - INFO - Hydra configuration loaded successfully for reconstruction experiment.\n",
      "2025-06-05 00:09:10,636 - __main__ - INFO - Experiment name: phase2_ijepa_voxel_reconstruction\n",
      "2025-06-05 00:09:10,636 - __main__ - INFO - Task type: voxel_reconstruction\n",
      "2025-06-05 00:09:10,636 - __main__ - INFO - Probe types: ['voxel']\n",
      "2025-06-05 00:09:10,635 - __main__ - INFO - Hydra configuration loaded successfully for reconstruction experiment.\n",
      "2025-06-05 00:09:10,636 - __main__ - INFO - Experiment name: phase2_ijepa_voxel_reconstruction\n",
      "2025-06-05 00:09:10,636 - __main__ - INFO - Task type: voxel_reconstruction\n",
      "2025-06-05 00:09:10,636 - __main__ - INFO - Probe types: ['voxel']\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "CONFIG_PATH = \"../configs\"\n",
    "CONFIG_NAME = \"exp_ijepa_reconstruction\"  # Use the new restructured config with defaults\n",
    "\n",
    "cfg: Optional[DictConfig] = None\n",
    "\n",
    "if GlobalHydra.instance().is_initialized():\n",
    "    logger.info(\"Clearing existing Hydra global state.\")\n",
    "    GlobalHydra.instance().clear()\n",
    "\n",
    "try:\n",
    "    project_root = Path(os.getcwd()).parent \n",
    "    data_dir_abs = project_root / \"data\" \n",
    "    os.environ[\"DATA_DIR\"] = str(data_dir_abs)\n",
    "    \n",
    "    logger.info(f\"Initializing Hydra with config_path: '{CONFIG_PATH}' relative to {os.getcwd()}\")\n",
    "    initialize(version_base=None, config_path=CONFIG_PATH, job_name=\"reconstruction_experiment\")\n",
    "    \n",
    "    logger.info(f\"Composing configuration with config_name: '{CONFIG_NAME}'\")\n",
    "    cfg = compose(config_name=CONFIG_NAME) \n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error initializing Hydra or loading configuration: {e}\", exc_info=True)\n",
    "    cfg = None \n",
    "\n",
    "if cfg:\n",
    "    logger.info(\"Hydra configuration loaded successfully for reconstruction experiment.\")\n",
    "    logger.info(f\"Experiment name: {cfg.experiment.name}\")\n",
    "    logger.info(f\"Task type: {cfg.probing.task_type}\")\n",
    "    logger.info(f\"Probe types: {cfg.probing.probe_types}\")\n",
    "\n",
    "else:\n",
    "    logger.error(\"Failed to load Hydra configuration. Please check paths and config files.\")\n",
    "\n",
    "# Quick check for critical reconstruction settings\n",
    "if cfg and cfg.probing.task_type != \"voxel_reconstruction\":\n",
    "    logger.warning(f\"Configured task_type is '{cfg.probing.task_type}', expected 'voxel_reconstruction' for this notebook.\")\n",
    "if cfg and \"voxel\" not in cfg.probing.probe_types:\n",
    "    logger.warning(f\"Configured probe_types are '{cfg.probing.probe_types}', 'voxel' probe might not run.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7188d",
   "metadata": {},
   "source": [
    "## Running the Reconstruction Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "003360ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:09:10,650 - __main__ - INFO - Starting reconstruction experiment execution\n",
      "2025-06-05 00:09:10,650 - __main__ - INFO - Using device: mps\n",
      "2025-06-05 00:09:10,650 - __main__ - INFO - Using device: mps\n",
      "2025-06-05 00:09:10,943 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "2025-06-05 00:09:10,943 - wandb.jupyter - ERROR - Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdruhin-bhowal\u001b[0m (\u001b[33mcse493g1_drn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdruhin-bhowal\u001b[0m (\u001b[33mcse493g1_drn\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.20.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/druhi/Documents/+Programming/GitHub/LatentInvestigation/notebooks/wandb/run-20250605_000912-51u2dq12</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cse493g1_drn/latent-investigation/runs/51u2dq12' target=\"_blank\">phase2_ijepa_voxel_reconstruction_reconstruction</a></strong> to <a href='https://wandb.ai/cse493g1_drn/latent-investigation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cse493g1_drn/latent-investigation' target=\"_blank\">https://wandb.ai/cse493g1_drn/latent-investigation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cse493g1_drn/latent-investigation/runs/51u2dq12' target=\"_blank\">https://wandb.ai/cse493g1_drn/latent-investigation/runs/51u2dq12</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstruction_results = None\n",
    "if cfg:\n",
    "    logger.info(\"Starting reconstruction experiment execution\")\n",
    "    experiment = ReconstructionExperiment(cfg)\n",
    "else:\n",
    "    logger.error(\"Configuration not loaded. Cannot start experiment.\")\n",
    "    experiment = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363288db",
   "metadata": {},
   "source": [
    "### Load Source Data and Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbee6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:09:14,322 - src.models.model_loader - INFO - Loading timm model 'facebook/vit_huge_patch14_224_ijepa'\n",
      "2025-06-05 00:09:19,344 - timm.models._builder - INFO - Loading pretrained weights from url (https://dl.fbaipublicfiles.com/ijepa/IN1K-vit.h.14-300e.pth.tar)\n",
      "2025-06-05 00:09:19,344 - timm.models._builder - INFO - Loading pretrained weights from url (https://dl.fbaipublicfiles.com/ijepa/IN1K-vit.h.14-300e.pth.tar)\n",
      "2025-06-05 00:09:21,333 - src.models.reconstruction_feature_extractor - INFO - Loaded and froze ijepa on mps.\n",
      "2025-06-05 00:09:21,334 - __main__ - INFO - Loaded ijepa reconstruction feature extractor\n",
      "2025-06-05 00:09:21,333 - src.models.reconstruction_feature_extractor - INFO - Loaded and froze ijepa on mps.\n",
      "2025-06-05 00:09:21,334 - __main__ - INFO - Loaded ijepa reconstruction feature extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created train DataLoader with 2451 samples, batch size 32.\n",
      "Created val DataLoader with 525 samples, batch size 32.\n",
      "Created test DataLoader with 525 samples, batch size 32.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if experiment:\n",
    "    image_feature_extractor = experiment.load_reconstruction_feature_extractor()\n",
    "    \n",
    "    extraction_config = cfg.models.get(\"feature_extraction\", {})\n",
    "    layers_to_probe = extraction_config.get(\"layers\", [0, 2, 5, 8, 11]) \n",
    "    image_feature_type = extraction_config.get(\"feature_type\", \"cls_token\")\n",
    "\n",
    "    train_source_loader, val_source_loader, test_source_loader = experiment.load_source_dataset()\n",
    "    \n",
    "    reconstruction_pipeline = ReconstructionPipeline(\n",
    "        image_pipeline=image_feature_extractor,\n",
    "        device=experiment.device,\n",
    "        cache_dir=str(experiment.cache_dir / \"processed_reconstruction_data\")\n",
    "    )\n",
    "else:\n",
    "    logger.error(\"Experiment not initialized. Skipping feature extractor and dataset loading.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75494f",
   "metadata": {},
   "source": [
    "### Process Data and Train VoxelProbes for Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19051df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:09:21,394 - __main__ - INFO - Will train VoxelProbes for layers: [2, 4, 6, 8, 10, 11]\n",
      "Processing Layers:   0%|          | 0/6 [00:00<?, ?it/s]2025-06-05 00:09:21,457 - __main__ - INFO - Processing layer 2 for reconstruction...\n",
      "2025-06-05 00:09:21,458 - src.probing.base_pipeline - INFO - Processing 76 batches...\n",
      "Processing Layers:   0%|          | 0/6 [00:00<?, ?it/s]2025-06-05 00:09:21,457 - __main__ - INFO - Processing layer 2 for reconstruction...\n",
      "2025-06-05 00:09:21,458 - src.probing.base_pipeline - INFO - Processing 76 batches...\n",
      "2025-06-05 00:09:26,411 - src.models.base_feature_extractor - INFO - Processing 768 images in chunks of 8\n",
      "2025-06-05 00:09:26,411 - src.models.base_feature_extractor - INFO - Processing 768 images in chunks of 8\n",
      "\n",
      "Aborted!\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "if experiment:\n",
    "    reconstruction_results = {}\n",
    "\n",
    "    if \"voxel\" not in cfg.probing.probe_types:\n",
    "        logger.error(f\"'voxel' not in configured probe_types: {cfg.probing.probe_types}. VoxelProbes will not be trained.\")\n",
    "    else:\n",
    "        logger.info(f\"Will train VoxelProbes for layers: {layers_to_probe}\")\n",
    "\n",
    "        for layer_idx in tqdm(layers_to_probe, desc=\"Processing Layers\"):\n",
    "            logger.info(f\"Processing layer {layer_idx} for reconstruction...\")\n",
    "\n",
    "            # Use the updated method with new API\n",
    "            train_input_ds, val_input_ds, test_input_ds = experiment.prepare_reconstruction_input_datasets_for_layer(\n",
    "                reconstruction_pipeline=reconstruction_pipeline,\n",
    "                train_source_loader=train_source_loader,\n",
    "                val_source_loader=val_source_loader,\n",
    "                test_source_loader=test_source_loader,\n",
    "                layer=layer_idx,\n",
    "                image_feature_type=image_feature_type,\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Layer {layer_idx}: Train Input Dataset size: {len(train_input_ds)}\")\n",
    "            logger.info(f\"Layer {layer_idx}: Val Input Dataset size: {len(val_input_ds)}\")\n",
    "            logger.info(f\"Layer {layer_idx}: Test Input Dataset size: {len(test_input_ds)}\")\n",
    "\n",
    "            # Create DataLoaders from the datasets\n",
    "            processed_batch_size = cfg.training.get(\"batch_size\", 32)\n",
    "            \n",
    "            train_processed_loader = DataLoader(\n",
    "                train_input_ds,\n",
    "                batch_size=processed_batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=cfg.get(\"num_workers\", 4),\n",
    "                pin_memory=True\n",
    "            )\n",
    "            \n",
    "            val_processed_loader = DataLoader(\n",
    "                val_input_ds,\n",
    "                batch_size=processed_batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=cfg.get(\"num_workers\", 4),\n",
    "                pin_memory=True\n",
    "            )\n",
    "            \n",
    "            test_processed_loader = DataLoader(\n",
    "                test_input_ds,\n",
    "                batch_size=processed_batch_size,\n",
    "                shuffle=False,\n",
    "                num_workers=cfg.get(\"num_workers\", 4),\n",
    "                pin_memory=True\n",
    "            )\n",
    "\n",
    "            # Get feature dimension from sample\n",
    "            sample_processed_data = train_input_ds[0][\"processed_views\"]\n",
    "            input_feature_dim_for_probe = sample_processed_data.numel() \n",
    "            logger.info(f\"Input feature dimension for VoxelProbe at layer {layer_idx}: {input_feature_dim_for_probe} (Shape of sample: {sample_processed_data.shape})\")\n",
    "\n",
    "            logger.info(f\"Running VoxelProbe on layer {layer_idx}...\")\n",
    "            probe_run_results = experiment.run_voxel_probe_experiment(\n",
    "                train_processed_loader=train_processed_loader,\n",
    "                val_processed_loader=val_processed_loader,\n",
    "                test_processed_loader=test_processed_loader,\n",
    "                feature_dim=input_feature_dim_for_probe,\n",
    "                layer=layer_idx,\n",
    "            )\n",
    "            reconstruction_results[f\"layer_{layer_idx}\"] = {\"voxel\": probe_run_results}\n",
    "\n",
    "else:\n",
    "    logger.error(\"Experiment not initialized. Skipping layer processing and probe training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203594fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment and reconstruction_results:\n",
    "    logger.info(\"Saving reconstruction experiment results...\")\n",
    "    result_file_path = experiment.save_results(reconstruction_results)\n",
    "    logger.info(f\"Results saved to: {result_file_path}\")\n",
    "else:\n",
    "    logger.warning(\"No results to save or experiment not run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0bcdeb",
   "metadata": {},
   "source": [
    "### Analyze and Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.layer_analysis import analyze_experiment_results\n",
    "\n",
    "if experiment and reconstruction_results and 'result_file_path' in locals():\n",
    "    logger.info(\"Analyzing reconstruction results...\")\n",
    "\n",
    "    analyze_experiment_results(\n",
    "        results_file=result_file_path,\n",
    "        output_dir=Path(result_file_path).parent\n",
    "    )\n",
    "else:\n",
    "    logger.warning(\"No results to analyze or result file path not available.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LatentInvestigation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
